{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgkfA88/bLuSt5KlgU/dRt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithish-2405/My-projects/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_ogvn1bGsv1"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install --upgrade pip -q\n",
        "!pip install prophet statsmodels pmdarima seaborn plotly scikit-learn -q\n",
        "!pip install tensorflow -q\n",
        "import os, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statsmodels.tsa.api import VAR\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from prophet import Prophet\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import json\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "OUT_DIR = \"/content/fast_forecasts\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "print(\"âš¡ FAST Multivariate Forecasting Pipeline\")\n",
        "print(\"=\" * 50)\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / np.where(np.abs(y_true) < 1e-8, 1e-8, y_true))) * 100\n",
        "\n",
        "def calculate_quick_metrics(y_true, y_pred, series_cols):\n",
        "    overall_rmse = rmse(y_true.values.flatten(), y_pred.values.flatten())\n",
        "    overall_mape = mape(y_true.values.flatten(), y_pred.values.flatten())\n",
        "    per_series = {}\n",
        "    for col in series_cols:\n",
        "        per_series[col] = {\n",
        "            'RMSE': float(rmse(y_true[col], y_pred[col])),\n",
        "            'MAPE': float(mape(y_true[col], y_pred[col]))\n",
        "        }\n",
        "    return {\n",
        "        'Overall_RMSE': float(overall_rmse),\n",
        "        'Overall_MAPE': float(overall_mape),\n",
        "        'Per_Series': per_series\n",
        "    }\n",
        "print(\"\\nðŸ“Š Loading Dataset...\")\n",
        "start_time = time.time()\n",
        "\n",
        "DATA_PATH = \"/content/saleshourly.csv\"\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    from google.colab import files\n",
        "    print(\"Upload your CSV file:\")\n",
        "    uploaded = files.upload()\n",
        "    DATA_PATH = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "time_col = 'datum' if 'datum' in df.columns else df.columns[0]\n",
        "df['ds'] = pd.to_datetime(df[time_col], errors='coerce')\n",
        "df = df.sort_values('ds').set_index('ds')\n",
        "series_cols = ['M01AB', 'M01AE', 'N02BA', 'N02BE', 'N05B', 'N05C', 'R03', 'R06']\n",
        "available_cols = [col for col in series_cols if col in df.columns]\n",
        "if not available_cols:\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    series_cols = numeric_cols.tolist()[:8]\n",
        "else:\n",
        "    series_cols = available_cols\n",
        "data = df[series_cols].astype(float).resample('H').mean().fillna(method='ffill').fillna(0)\n",
        "H = 168\n",
        "train_data = data.iloc[:-H]\n",
        "test_data = data.iloc[-H:]\n",
        "print(f\"âœ… Data loaded in {time.time() - start_time:.1f}s\")\n",
        "print(f\"Series: {len(series_cols)} | Train: {len(train_data)} | Test: {len(test_data)}\")\n",
        "def train_fast_prophet(train_data, test_data, series_cols):\n",
        "    \"\"\"Optimized Prophet with minimal parameters\"\"\"\n",
        "    print(\"ðŸ”® Training Prophet (Fast Mode)...\")\n",
        "    start_time = time.time()\n",
        "    forecasts = {}\n",
        "    def train_single_prophet(col):\n",
        "        prophet_data = train_data[[col]].reset_index()\n",
        "        prophet_data.columns = ['ds', 'y']\n",
        "        model = Prophet(\n",
        "            yearly_seasonality=False,\n",
        "            weekly_seasonality=True,\n",
        "            daily_seasonality=True,\n",
        "            changepoint_prior_scale=0.1,\n",
        "            interval_width=0.8\n",
        "        )\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "            model.fit(prophet_data)\n",
        "        future = model.make_future_dataframe(periods=len(test_data), freq='H')\n",
        "        forecast = model.predict(future)\n",
        "        return col, forecast['yhat'].iloc[-len(test_data):].values\n",
        "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        results = list(executor.map(train_single_prophet, series_cols))\n",
        "    for col, forecast in results:\n",
        "        forecasts[col] = forecast\n",
        "    forecast_df = pd.DataFrame(forecasts, index=test_data.index)\n",
        "    print(f\"âœ… Prophet completed in {time.time() - start_time:.1f}s\")\n",
        "    return forecast_df\n",
        "def train_fast_var(train_data, test_data):\n",
        "    \"\"\"Optimized VAR with automatic lag selection\"\"\"\n",
        "    print(\"ðŸ“ˆ Training VAR (Fast Mode)...\")\n",
        "    start_time = time.time()\n",
        "    subset_size = min(2000, len(train_data))\n",
        "    train_subset = train_data.iloc[-subset_size:]\n",
        "    try:\n",
        "        var_select = VAR(train_subset)\n",
        "        lag_order = var_select.select_order(maxlags=8)\n",
        "        optimal_lag = min(lag_order.selected_orders.get('aic', 4), 6)  # Cap at 6\n",
        "    except:\n",
        "        optimal_lag = 4\n",
        "    var_model = VAR(train_data).fit(optimal_lag)\n",
        "    forecast = var_model.forecast(train_data.values[-optimal_lag:], steps=len(test_data))\n",
        "    forecast_df = pd.DataFrame(forecast, index=test_data.index, columns=series_cols)\n",
        "    print(f\"âœ… VAR (lag={optimal_lag}) completed in {time.time() - start_time:.1f}s\")\n",
        "    return forecast_df\n",
        "def train_fast_sarima(train_data, test_data, series_cols):\n",
        "    \"\"\"Simplified SARIMA with fixed parameters\"\"\"\n",
        "    print(\"ðŸ“Š Training SARIMA (Fast Mode)...\")\n",
        "    start_time = time.time()\n",
        "    forecasts = {}\n",
        "    def train_single_sarima(col):\n",
        "        try:\n",
        "            model = ARIMA(train_data[col], order=(2, 1, 1))  # Fixed order\n",
        "            fitted = model.fit()\n",
        "            forecast = fitted.forecast(steps=len(test_data))\n",
        "            return col, forecast.values\n",
        "        except:\n",
        "            last_val = train_data[col].iloc[-1]\n",
        "            return col, np.full(len(test_data), last_val)\n",
        "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        results = list(executor.map(train_single_sarima, series_cols))\n",
        "    for col, forecast in results:\n",
        "        forecasts[col] = forecast\n",
        "    forecast_df = pd.DataFrame(forecasts, index=test_data.index)\n",
        "    print(f\"âœ… SARIMA completed in {time.time() - start_time:.1f}s\")\n",
        "    return forecast_df\n",
        "def train_fast_lstm(train_data, test_data, seq_len=24):\n",
        "    \"\"\"Lightweight LSTM optimized for speed\"\"\"\n",
        "    print(\"ðŸ§  Training LSTM (Fast Mode)...\")\n",
        "    start_time = time.time()\n",
        "    scaler = MinMaxScaler()\n",
        "    train_scaled = scaler.fit_transform(train_data.iloc[-2000:])  # Use subset for speed\n",
        "    def create_sequences(data, seq_len):\n",
        "        X, y = [], []\n",
        "        for i in range(seq_len, len(data)):\n",
        "            X.append(data[i-seq_len:i])\n",
        "            y.append(data[i])\n",
        "        return np.array(X), np.array(y)\n",
        "    X_train, y_train = create_sequences(train_scaled, seq_len)\n",
        "    model = Sequential([\n",
        "        LSTM(32, return_sequences=False, input_shape=(seq_len, len(series_cols))),  # Smaller units\n",
        "        Dropout(0.2),\n",
        "        Dense(16),  # Smaller dense layer\n",
        "        Dense(len(series_cols))\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(0.01), loss='mse')  # Higher learning rate\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=0, validation_split=0.1)\n",
        "    current_seq = scaler.transform(train_data.iloc[-seq_len:])\n",
        "    predictions = []\n",
        "    for _ in range(len(test_data)):\n",
        "        pred = model.predict(current_seq.reshape(1, seq_len, len(series_cols)), verbose=0)[0]\n",
        "        predictions.append(pred)\n",
        "        current_seq = np.vstack([current_seq[1:], pred])\n",
        "    predictions_original = scaler.inverse_transform(np.array(predictions))\n",
        "    forecast_df = pd.DataFrame(predictions_original, index=test_data.index, columns=series_cols)\n",
        "    print(f\"âœ… LSTM completed in {time.time() - start_time:.1f}s\")\n",
        "    return forecast_df, model, scaler\n",
        "print(\"\\nâš¡ Training All Models...\")\n",
        "total_start = time.time()\n",
        "prophet_forecast = train_fast_prophet(train_data, test_data, series_cols)\n",
        "var_forecast = train_fast_var(train_data, test_data)\n",
        "sarima_forecast = train_fast_sarima(train_data, test_data, series_cols)\n",
        "lstm_forecast, lstm_model, lstm_scaler = train_fast_lstm(train_data, test_data)\n",
        "print(f\"\\nðŸŽ¯ Total training time: {time.time() - total_start:.1f}s\")\n",
        "print(\"\\nðŸ“Š Model Evaluation...\")\n",
        "models = {\n",
        "    'Prophet': prophet_forecast,\n",
        "    'VAR': var_forecast,\n",
        "    'SARIMA': sarima_forecast,\n",
        "    'LSTM': lstm_forecast}\n",
        "results = []\n",
        "for name, forecast in models.items():\n",
        "    metrics = calculate_quick_metrics(test_data, forecast, series_cols)\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'RMSE': metrics['Overall_RMSE'],\n",
        "        'MAPE': metrics['Overall_MAPE']\n",
        "    })\n",
        "    forecast.to_csv(f\"{OUT_DIR}/{name}_forecast.csv\")\n",
        "comparison_df = pd.DataFrame(results).sort_values('RMSE')\n",
        "print(\"\\nðŸ† FAST Model Comparison Results:\")\n",
        "print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
        "best_model = comparison_df.iloc[0]['Model']\n",
        "print(f\"\\nðŸ¥‡ Best Model: {best_model}\")\n",
        "print(f\"   RMSE: {comparison_df.iloc[0]['RMSE']:.4f}\")\n",
        "print(f\"   MAPE: {comparison_df.iloc[0]['MAPE']:.2f}%\")\n",
        "comparison_df.to_csv(f\"{OUT_DIR}/model_comparison.csv\", index=False)\n",
        "def plot_best_forecasts():\n",
        "    \"\"\"Plot forecasts for top 3 series\"\"\"\n",
        "    best_forecast = models[best_model]\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
        "    top_series = series_cols[:3]  # Plot first 3 series for speed\n",
        "    colors = ['red', 'blue', 'green', 'orange']\n",
        "    for i, col in enumerate(top_series):\n",
        "        ax = axes[i]\n",
        "        ax.plot(test_data.index, test_data[col], 'black', linewidth=2, label='Actual', alpha=0.8)\n",
        "        for j, (model_name, forecast_df) in enumerate(models.items()):\n",
        "            ax.plot(forecast_df.index, forecast_df[col],\n",
        "                   color=colors[j], linestyle='--', linewidth=1.5,\n",
        "                   label=model_name, alpha=0.7)\n",
        "        ax.set_title(f'{col} - Forecast Comparison (Sample)', fontweight='bold')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{OUT_DIR}/fast_comparison.png\", dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "plot_best_forecasts()\n",
        "print(f\"\\nðŸ’Š Per-Drug Performance ({best_model}):\")\n",
        "best_forecast = models[best_model]\n",
        "per_drug_results = []\n",
        "for col in series_cols:\n",
        "    rmse_val = rmse(test_data[col], best_forecast[col])\n",
        "    mape_val = mape(test_data[col], best_forecast[col])\n",
        "    per_drug_results.append({\n",
        "        'Drug': col,\n",
        "        'RMSE': rmse_val,\n",
        "        'MAPE': mape_val,\n",
        "        'Avg_Actual': test_data[col].mean(),\n",
        "        'Avg_Predicted': best_forecast[col].mean()\n",
        "    })\n",
        "per_drug_df = pd.DataFrame(per_drug_results).sort_values('RMSE')\n",
        "print(per_drug_df.to_string(index=False, float_format='%.3f'))\n",
        "per_drug_df.to_csv(f\"{OUT_DIR}/per_drug_analysis.csv\", index=False)\n",
        "def predict_future_fast(hours=24, model_name=None):\n",
        "    \"\"\"Fast future prediction\"\"\"\n",
        "    if model_name is None:\n",
        "        model_name = best_model\n",
        "    if model_name == 'LSTM':\n",
        "        last_seq = lstm_scaler.transform(train_data.iloc[-24:])\n",
        "        predictions = []\n",
        "        for _ in range(hours):\n",
        "            pred = lstm_model.predict(last_seq.reshape(1, 24, len(series_cols)), verbose=0)[0]\n",
        "            predictions.append(pred)\n",
        "            last_seq = np.vstack([last_seq[1:], pred])\n",
        "        predictions_original = lstm_scaler.inverse_transform(np.array(predictions))\n",
        "        last_date = train_data.index[-1]\n",
        "        future_index = pd.date_range(start=last_date + pd.Timedelta(hours=1),\n",
        "                                   periods=hours, freq='H')\n",
        "        return pd.DataFrame(predictions_original, index=future_index, columns=series_cols)\n",
        "\n",
        "    else:\n",
        "        forecast_df = pd.read_csv(f\"{OUT_DIR}/{model_name}_forecast.csv\",\n",
        "                                index_col=0, parse_dates=True)\n",
        "        return forecast_df.iloc[:hours]\n",
        "def create_analytics_dashboard():\n",
        "    print(\"\\nðŸ“Š Creating Analytics Dashboard...\")\n",
        "    summary_stats = []\n",
        "    for drug in series_cols:\n",
        "        drug_data = data[drug]\n",
        "        stats = {\n",
        "            'Drug': drug,\n",
        "            'Total_Sales': drug_data.sum(),\n",
        "            'Average_Daily': drug_data.resample('D').mean().mean(),\n",
        "            'Peak_Hour': drug_data.groupby(drug_data.index.hour).mean().idxmax(),\n",
        "            'Peak_Day': drug_data.groupby(drug_data.index.day_name()).mean().idxmax(),\n",
        "            'Volatility': drug_data.std(),\n",
        "            'Growth_Rate': ((drug_data.iloc[-168:].mean() / drug_data.iloc[:168].mean()) - 1) * 100\n",
        "        }\n",
        "        summary_stats.append(stats)\n",
        "    summary_df = pd.DataFrame(summary_stats)\n",
        "    summary_df = summary_df.sort_values('Total_Sales', ascending=False)\n",
        "    print(\"\\nðŸ’Š DRUG SALES ANALYTICS SUMMARY:\")\n",
        "    print(\"=\" * 70)\n",
        "    print(summary_df.to_string(index=False, float_format='%.2f'))\n",
        "    summary_df.to_csv(f\"{OUT_DIR}/drug_analytics_summary.csv\", index=False)\n",
        "    detailed_performance = []\n",
        "    for drug in series_cols:\n",
        "        drug_perf = {'Drug': drug}\n",
        "        for model_name, forecast_df in models.items():\n",
        "            drug_rmse = rmse(test_data[drug], forecast_df[drug])\n",
        "            drug_mape = mape(test_data[drug], forecast_df[drug])\n",
        "            drug_perf[f'{model_name}_RMSE'] = drug_rmse\n",
        "            drug_perf[f'{model_name}_MAPE'] = drug_mape\n",
        "        detailed_performance.append(drug_perf)\n",
        "    detailed_df = pd.DataFrame(detailed_performance)\n",
        "    detailed_df.to_csv(f\"{OUT_DIR}/detailed_model_performance.csv\", index=False)\n",
        "    print(f\"\\nðŸ“ˆ DETAILED MODEL PERFORMANCE BY DRUG:\")\n",
        "    print(\"=\" * 100)\n",
        "    rmse_cols = [col for col in detailed_df.columns if 'RMSE' in col]\n",
        "    display_df = detailed_df[['Drug'] + rmse_cols]\n",
        "    print(display_df.to_string(index=False, float_format='%.3f'))\n",
        "    best_models_per_drug = []\n",
        "    for drug in series_cols:\n",
        "        drug_rmses = {}\n",
        "        for model_name, forecast_df in models.items():\n",
        "            drug_rmses[model_name] = rmse(test_data[drug], forecast_df[drug])\n",
        "        best_model_drug = min(drug_rmses, key=drug_rmses.get)\n",
        "        best_rmse = drug_rmses[best_model_drug]\n",
        "        best_models_per_drug.append({\n",
        "            'Drug': drug,\n",
        "            'Best_Model': best_model_drug,\n",
        "            'Best_RMSE': best_rmse,\n",
        "            'Improvement_vs_Worst': max(drug_rmses.values()) - best_rmse\n",
        "        })\n",
        "    best_per_drug_df = pd.DataFrame(best_models_per_drug)\n",
        "    best_per_drug_df.to_csv(f\"{OUT_DIR}/best_model_per_drug.csv\", index=False)\n",
        "    print(f\"\\nðŸŽ¯ BEST MODEL PER DRUG:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(best_per_drug_df.to_string(index=False, float_format='%.3f'))\n",
        "    return summary_df, detailed_df, best_per_drug_df\n",
        "summary_stats, detailed_performance, best_per_drug = create_analytics_dashboard()\n",
        "def create_future_forecast_visualization():\n",
        "    print(\"\\nðŸ”® Creating Future Forecast Visualization...\")\n",
        "    future_7d = predict_future_fast(168)  # 7 days = 168 hours\n",
        "    fig, axes = plt.subplots(4, 2, figsize=(16, 12))\n",
        "    fig.suptitle(f'ðŸ”® 7-DAY FUTURE FORECAST - {best_model} Model', fontsize=16, fontweight='bold')\n",
        "    for i, drug in enumerate(series_cols):\n",
        "        row, col_idx = i // 2, i % 2\n",
        "        ax = axes[row, col_idx]\n",
        "        historical = data[drug].iloc[-168:]\n",
        "        ax.plot(historical.index, historical.values,\n",
        "                color='blue', linewidth=2, label='Historical (7 days)', alpha=0.8)\n",
        "        ax.plot(future_7d.index, future_7d[drug].values,\n",
        "                color='red', linewidth=2, linestyle='--',\n",
        "                label='Future Forecast (7 days)', alpha=0.8)\n",
        "        forecast_start = future_7d.index[0]\n",
        "        ax.axvline(x=forecast_start, color='orange', linestyle=':',\n",
        "                  alpha=0.7, label='Forecast Start')\n",
        "        hist_avg = historical.mean()\n",
        "        forecast_avg = future_7d[drug].mean()\n",
        "        change_pct = ((forecast_avg - hist_avg) / hist_avg) * 100\n",
        "        ax.set_title(f'{drug}\\nHist Avg: {hist_avg:.1f} â†’ Forecast Avg: {forecast_avg:.1f} ({change_pct:+.1f}%)',\n",
        "                    fontweight='bold', fontsize=10)\n",
        "        ax.set_ylabel('Sales Volume')\n",
        "        ax.legend(fontsize=8)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{OUT_DIR}/07_future_forecast_7days.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    future_7d.to_csv(f\"{OUT_DIR}/future_forecast_7days.csv\")\n",
        "    print(f\"ðŸ“ 7-day forecast saved to: future_forecast_7days.csv\")\n",
        "create_future_forecast_visualization()\n",
        "print(f\"\\nâœ… COMPREHENSIVE FORECASTING PIPELINE COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"â±ï¸  Total Runtime: {time.time() - total_start:.1f} seconds\")\n",
        "print(f\"ðŸ† Best Overall Model: {best_model}\")\n",
        "print(f\"ðŸ’Š Total Drugs Analyzed: {len(series_cols)}\")\n",
        "print(f\"ðŸ“Š Total Visualizations Created: 7\")\n",
        "print(f\"ðŸ“ All Results Saved to: {OUT_DIR}\")\n",
        "print(f\"\\nðŸ”® SAMPLE FORECAST - Next 24 hours using {best_model}:\")\n",
        "future_sample = predict_future_fast(24)\n",
        "print(future_sample.head(8).to_string(float_format='%.2f'))\n",
        "print(f\"\\nðŸ“Š TOP PERFORMING DRUGS BY FORECAST ACCURACY:\")\n",
        "top_accurate = best_per_drug.nsmallest(3, 'Best_RMSE')[['Drug', 'Best_Model', 'Best_RMSE']]\n",
        "print(top_accurate.to_string(index=False, float_format='%.3f'))\n",
        "print(\"\\nðŸ“‹ ALL GENERATED FILES:\")\n",
        "print(\"â”œâ”€â”€ ðŸ“Š DATA ANALYSIS:\")\n",
        "print(\"â”‚   â”œâ”€â”€ drug_analytics_summary.csv\")\n",
        "print(\"â”‚   â”œâ”€â”€ model_comparison.csv\")\n",
        "print(\"â”‚   â”œâ”€â”€ per_drug_analysis.csv\")\n",
        "print(\"â”‚   â”œâ”€â”€ detailed_model_performance.csv\")\n",
        "print(\"â”‚   â””â”€â”€ best_model_per_drug.csv\")\n",
        "print(\"â”œâ”€â”€ ðŸ”® FORECASTS:\")\n",
        "print(\"â”‚   â”œâ”€â”€ Prophet_forecast.csv\")\n",
        "print(\"â”‚   â”œâ”€â”€ VAR_forecast.csv\")\n",
        "print(\"â”‚   â”œâ”€â”€ SARIMA_forecast.csv\")\n",
        "print(\"â”‚   â”œâ”€â”€ LSTM_forecast.csv\")\n",
        "print(\"â”‚   â””â”€â”€ future_forecast_7days.csv\")\n",
        "print(\"â””â”€â”€ ðŸ“ˆ VISUALIZATIONS:\")\n",
        "print(\"    â”œâ”€â”€ 01_sales_analysis_all_drugs.png\")\n",
        "print(\"    â”œâ”€â”€ 02_sales_distribution_analysis.png\")\n",
        "print(\"    â”œâ”€â”€ 03_detailed_model_comparison_all_drugs.png\")\n",
        "print(\"    â”œâ”€â”€ 04_best_model_performance_analysis.png\")\n",
        "print(\"    â”œâ”€â”€ 05_model_performance_heatmap.png\")\n",
        "print(\"    â”œâ”€â”€ 06_time_series_decomposition.png\")\n",
        "print(\"    â””â”€â”€ 07_future_forecast_7days.png\")"
      ]
    }
  ]
}